{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1eb68ba-8bef-48ee-b0da-87c00218715e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 4.6511\n",
      "Epoch [20/100], Loss: 3.8282\n",
      "Epoch [30/100], Loss: 2.9218\n",
      "Epoch [40/100], Loss: 2.0633\n",
      "Epoch [50/100], Loss: 1.4666\n",
      "Epoch [60/100], Loss: 1.1218\n",
      "Epoch [70/100], Loss: 0.9067\n",
      "Epoch [80/100], Loss: 0.7900\n",
      "Epoch [90/100], Loss: 0.7369\n",
      "Epoch [100/100], Loss: 0.7055\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the California housing dataset\n",
    "data = fetch_california_housing()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert the numpy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Define the neural network model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.fc1(x))\n",
    "        x = self.relu2(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "input_size = X_train.shape[1]\n",
    "model = Net(input_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1)%10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8612b0c7-fb57-4196-998f-d21d7f3d8450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
       "          37.88      , -122.23      ],\n",
       "       [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
       "          37.86      , -122.22      ],\n",
       "       [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
       "          37.85      , -122.24      ],\n",
       "       ...,\n",
       "       [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
       "          39.43      , -121.22      ],\n",
       "       [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
       "          39.43      , -121.32      ],\n",
       "       [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
       "          39.37      , -121.24      ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8192c961-bbc2-484a-842e-73ec319b9114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "184a13ac-1ad3-467a-b9a4-e3410ed2025a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.741019</td>\n",
       "      <td>1.614971</td>\n",
       "      <td>-0.295713</td>\n",
       "      <td>-0.177953</td>\n",
       "      <td>-0.717724</td>\n",
       "      <td>-0.075766</td>\n",
       "      <td>1.044339</td>\n",
       "      <td>-1.359761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.163541</td>\n",
       "      <td>-0.368623</td>\n",
       "      <td>0.003247</td>\n",
       "      <td>0.011572</td>\n",
       "      <td>-0.437714</td>\n",
       "      <td>-0.010153</td>\n",
       "      <td>1.020922</td>\n",
       "      <td>-0.820054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.523548</td>\n",
       "      <td>0.504158</td>\n",
       "      <td>-0.384646</td>\n",
       "      <td>-0.084150</td>\n",
       "      <td>-0.248707</td>\n",
       "      <td>-0.010234</td>\n",
       "      <td>1.016238</td>\n",
       "      <td>-1.324780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.926180</td>\n",
       "      <td>0.266127</td>\n",
       "      <td>-0.840016</td>\n",
       "      <td>-0.386927</td>\n",
       "      <td>-0.244332</td>\n",
       "      <td>0.014403</td>\n",
       "      <td>-0.730692</td>\n",
       "      <td>0.724106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.011848</td>\n",
       "      <td>0.583502</td>\n",
       "      <td>-0.606825</td>\n",
       "      <td>-0.146700</td>\n",
       "      <td>-0.008073</td>\n",
       "      <td>0.150447</td>\n",
       "      <td>-1.372326</td>\n",
       "      <td>1.223835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4123</th>\n",
       "      <td>1.186209</td>\n",
       "      <td>-0.447966</td>\n",
       "      <td>0.381138</td>\n",
       "      <td>-0.194598</td>\n",
       "      <td>0.234311</td>\n",
       "      <td>-0.007470</td>\n",
       "      <td>-0.941447</td>\n",
       "      <td>0.943987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4124</th>\n",
       "      <td>-0.097091</td>\n",
       "      <td>1.853002</td>\n",
       "      <td>-0.448035</td>\n",
       "      <td>-0.169439</td>\n",
       "      <td>-0.225081</td>\n",
       "      <td>-0.174395</td>\n",
       "      <td>1.006871</td>\n",
       "      <td>-1.434720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4125</th>\n",
       "      <td>0.463735</td>\n",
       "      <td>0.583502</td>\n",
       "      <td>-0.095625</td>\n",
       "      <td>-0.513243</td>\n",
       "      <td>-0.601345</td>\n",
       "      <td>-0.115546</td>\n",
       "      <td>0.800799</td>\n",
       "      <td>-1.194850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4126</th>\n",
       "      <td>-0.523548</td>\n",
       "      <td>0.504158</td>\n",
       "      <td>-0.357973</td>\n",
       "      <td>0.085547</td>\n",
       "      <td>-0.228581</td>\n",
       "      <td>-0.000968</td>\n",
       "      <td>-0.819677</td>\n",
       "      <td>0.684128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4127</th>\n",
       "      <td>0.113782</td>\n",
       "      <td>-0.685997</td>\n",
       "      <td>0.068749</td>\n",
       "      <td>-0.148456</td>\n",
       "      <td>0.296438</td>\n",
       "      <td>0.228091</td>\n",
       "      <td>-1.372326</td>\n",
       "      <td>1.243824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4128 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0    -0.741019  1.614971 -0.295713  -0.177953   -0.717724 -0.075766  1.044339   \n",
       "1    -0.163541 -0.368623  0.003247   0.011572   -0.437714 -0.010153  1.020922   \n",
       "2    -0.523548  0.504158 -0.384646  -0.084150   -0.248707 -0.010234  1.016238   \n",
       "3    -0.926180  0.266127 -0.840016  -0.386927   -0.244332  0.014403 -0.730692   \n",
       "4    -1.011848  0.583502 -0.606825  -0.146700   -0.008073  0.150447 -1.372326   \n",
       "...        ...       ...       ...        ...         ...       ...       ...   \n",
       "4123  1.186209 -0.447966  0.381138  -0.194598    0.234311 -0.007470 -0.941447   \n",
       "4124 -0.097091  1.853002 -0.448035  -0.169439   -0.225081 -0.174395  1.006871   \n",
       "4125  0.463735  0.583502 -0.095625  -0.513243   -0.601345 -0.115546  0.800799   \n",
       "4126 -0.523548  0.504158 -0.357973   0.085547   -0.228581 -0.000968 -0.819677   \n",
       "4127  0.113782 -0.685997  0.068749  -0.148456    0.296438  0.228091 -1.372326   \n",
       "\n",
       "      Longitude  \n",
       "0     -1.359761  \n",
       "1     -0.820054  \n",
       "2     -1.324780  \n",
       "3      0.724106  \n",
       "4      1.223835  \n",
       "...         ...  \n",
       "4123   0.943987  \n",
       "4124  -1.434720  \n",
       "4125  -1.194850  \n",
       "4126   0.684128  \n",
       "4127   1.243824  \n",
       "\n",
       "[4128 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pdf = pd.DataFrame(X_test, columns=data.feature_names)\n",
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c8b6a98-77af-4d5b-ae6d-a320a602c082",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+------------+------------+------------+------------+-----------+----------+\n",
      "|      MedInc|    HouseAge|    AveRooms|   AveBedrms|  Population|    AveOccup|   Latitude| Longitude|\n",
      "+------------+------------+------------+------------+------------+------------+-----------+----------+\n",
      "| -0.74101853|   1.6149706| -0.29571253| -0.17795317|  -0.7177242| -0.07576603|  1.0443388|-1.3597609|\n",
      "|  -0.1635414|  -0.3686225|0.0032469928|  0.01157152| -0.43771398|-0.010152793|  1.0209215|-0.8200542|\n",
      "| -0.52354825|  0.50415844| -0.38464627| -0.08415038| -0.24870707|-0.010233884|  1.0162381|-1.3247799|\n",
      "|  -0.9261799|  0.26612726|  -0.8400165| -0.38692707| -0.24433191| 0.014403454| -0.7306918| 0.7241065|\n",
      "|  -1.0118484|   0.5835022|  -0.6068254| -0.14670016|-0.008073272|  0.15044716| -1.3723255| 1.2238349|\n",
      "|  -0.4511803|    1.218252|  -0.5674745| -0.04344595|   -0.383462| -0.19109002|  1.0583892|-1.3547635|\n",
      "| -0.77940184| 0.107439816|  0.04742335| -0.18705839|  -0.6188456| 0.009825676| 0.88510126|-0.7001194|\n",
      "|  0.33172327|   1.0595645|  0.09551476| -0.28693205| -0.22070605| -0.10527463| -1.3114406| 1.1438783|\n",
      "|    0.800282|  -1.9554969| 0.012280249|  0.50189316| -0.37733677|-0.114659086| -1.0163827|0.97896796|\n",
      "|   1.5530759|  -0.2892788|   0.7268011|  -0.2577036|  -0.5925946| -0.00604933|-0.83841133|  0.839044|\n",
      "| -0.14170535|-0.051247627|  -0.7266378| -0.69964415|  -0.7894769| 0.009531216|  -1.367642| 1.2288321|\n",
      "|  0.19049588|  -1.7968096|   0.9891403|  0.18185335|  -1.0493613|  0.07476261|-0.83841133| 1.0039544|\n",
      "| 0.016488202|  0.26612726|-0.005680584| -0.29517394|  -0.5173419|-0.025493871|  0.9459862|-1.2648125|\n",
      "| -0.21543474|  0.66284585| 0.037852347| -0.31680351|  -0.4272136| -0.06283411|-0.71195793|0.94898427|\n",
      "|   -0.808726|  0.26612726| -0.90377903| -0.14293806|  0.31918868|  0.23300736| -0.7494256| 0.6541445|\n",
      "|-0.037656825|  0.50415844|  0.09610648| -0.10043379| -0.27758312|-0.073903725| -0.7072745|  0.769082|\n",
      "| -0.27806285|   0.5835022| -0.37179384| -0.02930664| -0.64509654| -0.17674711| -0.7306918|0.59417707|\n",
      "|   1.5183582|    1.218252|  0.15158443|-0.043277375| -0.52959234| -0.06362266| -0.7822098| 0.7091146|\n",
      "|   1.5848613| -0.13059135|   1.0759239| -0.15628804|  -0.3589611|0.0013800488| -0.8711955|0.87902224|\n",
      "|   -0.601781|   0.5835022|  0.09534762| -0.11449424|  0.22031008|-0.046855938|-0.13120915|0.26435637|\n",
      "+------------+------------+------------+------------+------------+------------+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "# Spark is somehow auto-converting Pandas float32 to DoubleType(), so forcing FloatType()\n",
    "schema = StructType([\n",
    "StructField(\"MedInc\",FloatType(),True),\n",
    "StructField(\"HouseAge\",FloatType(),True),\n",
    "StructField(\"AveRooms\",FloatType(),True),\n",
    "StructField(\"AveBedrms\",FloatType(),True),\n",
    "StructField(\"Population\",FloatType(),True),\n",
    "StructField(\"AveOccup\",FloatType(),True),\n",
    "StructField(\"Latitude\",FloatType(),True),\n",
    "StructField(\"Longitude\",FloatType(),True)\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(pdf, schema=schema)\n",
    "df.show(truncate=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4af618b-2600-442a-95ed-c4db5066bb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch_fn():\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    loaded_model = torch.load('model.pth')\n",
    "    \n",
    "    def predict(inputs):\n",
    "        torch_inputs = torch.from_numpy(inputs).to(device)\n",
    "        outputs = model(torch_inputs) # .flatten()\n",
    "        return outputs.detach().numpy()\n",
    "\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7b882e1-dc4f-48a4-b6e6-ad5046aa78e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.functions import predict_batch_udf\n",
    "\n",
    "classify = predict_batch_udf(predict_batch_fn,\n",
    "                             return_type=FloatType(),\n",
    "                             input_tensor_shapes=[[8]],\n",
    "                             batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f22093b-c711-4586-9e2f-23f6f16a4dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MedInc',\n",
       " 'HouseAge',\n",
       " 'AveRooms',\n",
       " 'AveBedrms',\n",
       " 'Population',\n",
       " 'AveOccup',\n",
       " 'Latitude',\n",
       " 'Longitude']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = df.columns\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb68c980-407a-4b53-8419-ba60ee9d32d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+------------+------------+------------+------------+-----------+----------+---------+\n",
      "|      MedInc|    HouseAge|    AveRooms|   AveBedrms|  Population|    AveOccup|   Latitude| Longitude|    preds|\n",
      "+------------+------------+------------+------------+------------+------------+-----------+----------+---------+\n",
      "| -0.74101853|   1.6149706| -0.29571253| -0.17795317|  -0.7177242| -0.07576603|  1.0443388|-1.3597609|1.9241145|\n",
      "|  -0.1635414|  -0.3686225|0.0032469928|  0.01157152| -0.43771398|-0.010152793|  1.0209215|-0.8200542|1.3536556|\n",
      "| -0.52354825|  0.50415844| -0.38464627| -0.08415038| -0.24870707|-0.010233884|  1.0162381|-1.3247799|1.5152398|\n",
      "|  -0.9261799|  0.26612726|  -0.8400165| -0.38692707| -0.24433191| 0.014403454| -0.7306918| 0.7241065|1.5755394|\n",
      "|  -1.0118484|   0.5835022|  -0.6068254| -0.14670016|-0.008073272|  0.15044716| -1.3723255| 1.2238349|1.7656959|\n",
      "|  -0.4511803|    1.218252|  -0.5674745| -0.04344595|   -0.383462| -0.19109002|  1.0583892|-1.3547635|1.9915309|\n",
      "| -0.77940184| 0.107439816|  0.04742335| -0.18705839|  -0.6188456| 0.009825676| 0.88510126|-0.7001194| 1.086676|\n",
      "|  0.33172327|   1.0595645|  0.09551476| -0.28693205| -0.22070605| -0.10527463| -1.3114406| 1.1438783|2.8794587|\n",
      "|    0.800282|  -1.9554969| 0.012280249|  0.50189316| -0.37733677|-0.114659086| -1.0163827|0.97896796|2.1750774|\n",
      "|   1.5530759|  -0.2892788|   0.7268011|  -0.2577036|  -0.5925946| -0.00604933|-0.83841133|  0.839044|3.2578032|\n",
      "| -0.14170535|-0.051247627|  -0.7266378| -0.69964415|  -0.7894769| 0.009531216|  -1.367642| 1.2288321|2.4779553|\n",
      "|  0.19049588|  -1.7968096|   0.9891403|  0.18185335|  -1.0493613|  0.07476261|-0.83841133| 1.0039544|2.0342894|\n",
      "| 0.016488202|  0.26612726|-0.005680584| -0.29517394|  -0.5173419|-0.025493871|  0.9459862|-1.2648125|1.9197291|\n",
      "| -0.21543474|  0.66284585| 0.037852347| -0.31680351|  -0.4272136| -0.06283411|-0.71195793|0.94898427|2.0826561|\n",
      "|   -0.808726|  0.26612726| -0.90377903| -0.14293806|  0.31918868|  0.23300736| -0.7494256| 0.6541445|1.3400757|\n",
      "|-0.037656825|  0.50415844|  0.09610648| -0.10043379| -0.27758312|-0.073903725| -0.7072745|  0.769082|1.9761388|\n",
      "| -0.27806285|   0.5835022| -0.37179384| -0.02930664| -0.64509654| -0.17674711| -0.7306918|0.59417707|1.9539348|\n",
      "|   1.5183582|    1.218252|  0.15158443|-0.043277375| -0.52959234| -0.06362266| -0.7822098| 0.7091146| 3.452544|\n",
      "|   1.5848613| -0.13059135|   1.0759239| -0.15628804|  -0.3589611|0.0013800488| -0.8711955|0.87902224|3.3080647|\n",
      "|   -0.601781|   0.5835022|  0.09534762| -0.11449424|  0.22031008|-0.046855938|-0.13120915|0.26435637|1.1740093|\n",
      "+------------+------------+------------+------------+------------+------------+-----------+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "/var/folders/kc/d5ch_lnd6dq1ngt4kzl13rk00000gn/T/ipykernel_48710/581798393.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "preds = df.withColumn(\"preds\", classify(F.struct(*columns)))\n",
    "preds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cbe7bb3-6fdf-4443-9fdd-034ffba2da38",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'show'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'show'"
     ]
    }
   ],
   "source": [
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "486a8c8d-79af-4954-a827-65a15c9c8f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-7.41018555e-01,  1.61497054e+00, -2.95712538e-01, ...,\n",
       "        -7.57660305e-02,  1.04433881e+00, -1.35976084e+00],\n",
       "       [-1.63541400e-01, -3.68622515e-01,  3.24699276e-03, ...,\n",
       "        -1.01527922e-02,  1.02092152e+00, -8.20054198e-01],\n",
       "       [-5.23548241e-01,  5.04158431e-01, -3.84646265e-01, ...,\n",
       "        -1.02338842e-02,  1.01623806e+00, -1.32477985e+00],\n",
       "       ...,\n",
       "       [ 4.63734519e-01,  5.83502153e-01, -9.56254733e-02, ...,\n",
       "        -1.15546226e-01,  8.00798993e-01, -1.19485048e+00],\n",
       "       [-5.23548241e-01,  5.04158431e-01, -3.57973122e-01, ...,\n",
       "        -9.67512299e-04, -8.19677481e-01,  6.84128202e-01],\n",
       "       [ 1.13781687e-01, -6.85997405e-01,  6.87490896e-02, ...,\n",
       "         2.28090968e-01, -1.37232553e+00,  1.24382398e+00]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2c25ff3-9a3e-4c2a-92ec-49a4674a4670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.938, 1.308, 1.438, ..., 2.947, 1.783, 1.35 ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba039462-de8e-4c9c-8f6e-e13110e8f39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cpu device                                                  (0 + 10) / 10]\n",
      "Using cpu device\n",
      "/var/folders/kc/d5ch_lnd6dq1ngt4kzl13rk00000gn/T/ipykernel_48710/581798393.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "/var/folders/kc/d5ch_lnd6dq1ngt4kzl13rk00000gn/T/ipykernel_48710/581798393.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "Using cpu device\n",
      "Using cpu device\n",
      "/var/folders/kc/d5ch_lnd6dq1ngt4kzl13rk00000gn/T/ipykernel_48710/581798393.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "/var/folders/kc/d5ch_lnd6dq1ngt4kzl13rk00000gn/T/ipykernel_48710/581798393.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "Using cpu device\n",
      "Using cpu device\n",
      "/var/folders/kc/d5ch_lnd6dq1ngt4kzl13rk00000gn/T/ipykernel_48710/581798393.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "/var/folders/kc/d5ch_lnd6dq1ngt4kzl13rk00000gn/T/ipykernel_48710/581798393.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "Using cpu device\n",
      "Using cpu device\n",
      "/var/folders/kc/d5ch_lnd6dq1ngt4kzl13rk00000gn/T/ipykernel_48710/581798393.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "/var/folders/kc/d5ch_lnd6dq1ngt4kzl13rk00000gn/T/ipykernel_48710/581798393.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "Using cpu device\n",
      "/var/folders/kc/d5ch_lnd6dq1ngt4kzl13rk00000gn/T/ipykernel_48710/581798393.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "/var/folders/kc/d5ch_lnd6dq1ngt4kzl13rk00000gn/T/ipykernel_48710/581798393.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "Using cpu device\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions = [x['preds'] for x in preds.select('preds').collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b88bad2-8f89-4cec-8ad9-1226fdfcd2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error on test set: 0.600892072953799\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Compute MAE\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "print(\"Mean Absolute Error on test set:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f344d96b-10da-4c4b-b10e-657fea0295e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3025a773-8031-468c-af2f-ad9dfde58177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9380, 1.3080, 1.4380,  ..., 2.9470, 1.7830, 1.3500],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc333d57-215c-4d3e-9eb5-b0923be799a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.9241, 1.3537, 1.5152,  ..., 2.5636, 1.6112, 1.9115])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf75136e-2ffa-405e-8dfc-582c397cb456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6946, dtype=torch.float64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(torch.tensor(y_test), torch.tensor(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9703f639-aea9-43e4-89e3-3bbce40dddd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[55.3222]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the neural network model using nn.Sequential\n",
    "input_size = 8  # Number of features in the California housing dataset\n",
    "test_model = nn.Sequential(\n",
    "    nn.Linear(input_size, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 1)\n",
    ")\n",
    "\n",
    "# Load the trained model's state if available\n",
    "# Uncomment the following lines if you have a saved model state\n",
    "# model.load_state_dict(torch.load('model.pth'))\n",
    "# model.eval()\n",
    "\n",
    "# Create an arbitrary input tensor with explicit feature values\n",
    "# Let's define explicit values for the 8 features:\n",
    "# - MedInc: Median income in block group\n",
    "# - HouseAge: Median house age in block group\n",
    "# - AveRooms: Average number of rooms per household\n",
    "# - AveBedrms: Average number of bedrooms per household\n",
    "# - Population: Block group population\n",
    "# - AveOccup: Average number of household members\n",
    "# - Latitude: Latitude coordinate\n",
    "# - Longitude: Longitude coordinate\n",
    "\n",
    "# For demonstration, we'll use the following values (made-up for this example):\n",
    "input_tensor = torch.tensor([\n",
    "    5.0,      # MedInc\n",
    "    30.0,     # HouseAge\n",
    "    6.0,      # AveRooms\n",
    "    1.0,      # AveBedrms\n",
    "    1000.0,   # Population\n",
    "    3.0,      # AveOccup\n",
    "    34.05,    # Latitude (e.g., Los Angeles)\n",
    "    -118.25   # Longitude (e.g., Los Angeles)\n",
    "], dtype=torch.float32)\n",
    "\n",
    "\n",
    "# Perform a forward pass through the model\n",
    "output = test_model(input_tensor.unsqueeze(0))\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c64016-6f2c-43f6-a719-e404f6d0162d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
